\documentclass[a4paper,12pt]{article}

% Packages
\usepackage{amsmath, amssymb, amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{geometry}
\usepackage{minted}
\geometry{margin=1in}

% Custom Theorem Styles
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}

% Custom Commands
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}

% Title Information
\title{\textbf{Deep Learning Notes}}
\author{Amir Nourinia}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
  These notes provide an introduction to neural networks, including theoretical foundations and practical implementation details.
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}
This course introduces neural networks with a hands-on approach. Each day consists of two lectures,
followed by a practical session to reinforce the material covered.

\section{Neural Networks}

\subsection{Perceptron}
A perceptron is a simple linear classifier that maps inputs to outputs.
To increase its capabilities, we introduce a nonlinear function that acts on the perceptron's output.
These nonlinear functions, called \textbf{activation functions}, help introduce complexity and allow neural
networks to model more sophisticated patterns.
\subsubsection{Perceptron's implementation}
\inputminted[frame=lines, fontsize=\scriptsize, linenos]{python}{../../blue/layers/dense_layer.py}

\subsection{Activation Functions}
Some common activation functions are:
\begin{itemize}
  \item \textbf{Sigmoid}: $\sigma(x) = \frac{1}{1+e^{-x}}$
  \item \textbf{ReLU}: $ReLU(x) = \max(0, x)$
  \item \textbf{Softmax}: $\sigma(z_i) = \frac{e^{z_i}}{\sum_{j} e^{z_j}}$
\end{itemize}
A good activation function should be:
\begin{itemize}
  \item Efficient to compute
  \item Easy to differentiate
  \item Numerically stable
\end{itemize}

\subsubsection{Activation Functions' implementation}
\inputminted[frame=lines, fontsize=\scriptsize, linenos]{python}{../../blue/activation_functions/activation_functions.py}

\section{Training Neural Networks}

\subsection{Loss Functions}
\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Loss Function]
  The loss function assigns a scalar loss value based on the current weights of the network.
\end{tcolorbox}

\subsection{Optimization Algorithms}
Optimization algorithms find optimal weights for a neural network by exploring the loss
landscape generated by the training data.

\subsubsection{Gradient Descent}
\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Gradient Descent]
  Gradient descent is an optimization algorithm used to minimize a function by iteratively moving in the 
  direction of the negative gradient.
\end{tcolorbox}

\subsubsection{Stochastic Gradient Descent (SGD)}
The Gradient Descent is a computationally heavy algorithm, hence we try to approximate it using the 
SGD algorithm. The approach is to select a subset of training data and calculate the Gradient Descent
on each of this training data points and find the mean of these values. This firstly removes the noisy 
characteristic of the case when we only calculate the Gradient Descent for single data point and secondly,
it is implementable in parallel scheme and hence it can be computed fast.

Mini-Batch TODO

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Stochastic Gradient Descent]
  SGD is a variant of gradient descent that updates weights using a randomly selected subset (mini-batch)
  of training data, reducing computational cost.
\end{tcolorbox}

\subsection{Backpropagation}
Backpropagation computes the gradient of the loss function with respect to each weight by propagating
errors backward from the output layer to the input layer.

\subsection{Learning Rate}
The learning rate controls the step size of weight updates. Choosing an appropriate learning rate is
crucial to ensure convergence and avoid divergence.

The learning rate can adapt itself based on the state of learning. This state can be a function of
different factors such as the weights, the rate and the slop of the gradient, etc.
There are different adaptive learning rate algorithms such as Adam, Adadelta, Adagrad, RMSProp.
The one that we usually use in practice is Adam.

\subsection{Regularization}
Using Regularization we try to generalize our method over unseen data. There are two different ways of regularization discussed
in the lecture. During the training process the model can start to memorize the data and this can lead to over-fitting.
Over fitting can hinder the ability of a model to generalize over the true distribution of the data.
\begin{itemize}
  \item Dropout
  \item Early Stopping
\end{itemize}

\subsubsection{Dropout}
Dropping out substitutes zero as the activation value of a randomly selected node during training. This forces
the network to learn new paths to reach the same value and hence the network does not rely on one node. I imagine it
as the information of that computation spreads over different topology.

\subsubsection{Early Stopping}
The idea of Early Stopping is to stop the training before over fitting happens.


\section{References}
\begin{enumerate}
  \item Goodfellow, I., Bengio, Y., \& Courville, A. (2016). \textit{Deep Learning}. MIT Press.
  \item LeCun, Y., Bengio, Y., \& Hinton, G. (2015). Deep learning. \textit{Nature}, 521(7553), 436-444.
  \item Bishop, C. M. (2006). \textit{Pattern Recognition and Machine Learning}. Springer.
\end{enumerate}

\end{document}
